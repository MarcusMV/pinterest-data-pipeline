{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from functools import reduce\n",
    "from operator import and_\n",
    "\n",
    "# Clean df_user table\n",
    "# Define schema for JSON data\n",
    "fields = [\n",
    "    ('ind', IntegerType()), \n",
    "    ('first_name', StringType()), \n",
    "    ('last_name', StringType()), \n",
    "    ('age', IntegerType()), \n",
    "    ('date_joined', TimestampType()), \n",
    "]\n",
    "\n",
    "schema = StructType([StructField(field[0], field[1]) for field in fields])\n",
    "\n",
    "# Parse JSON in the 'data' column\n",
    "df = df_user.withColumn('parsed_data', from_json(col('data'), schema))\n",
    "\n",
    "# Remove records where any keys are null/did not match schema\n",
    "conditions = [col(f'parsed_data.{field[0]}').isNotNull() for field in fields]\n",
    "combined_condition = reduce(and_, conditions)\n",
    "df = df.filter(combined_condition)\n",
    "\n",
    "# Extract individual fields from parsed_data column\n",
    "for field in fields:\n",
    "    df = df.withColumn(field[0], df.parsed_data.getField(field[0]))\n",
    "\n",
    "# Concatenate first_name and last_name to user_name column\n",
    "df = df.withColumn('user_name', F.concat_ws(' ', df.first_name, df.last_name))\n",
    "\n",
    "df_user_clean = df.select('ind', 'user_name', 'age', 'date_joined')\n",
    "\n",
    "query_user = write_to_delta_table(df_user_clean, '12c5e9eb47cb_user_table')\n",
    "# display(df_user_clean)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
